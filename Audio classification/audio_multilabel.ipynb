{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label prediction with Planet Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9339ba12e06c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchaudio'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To have reproducible results with fastai you must also set num_workers=1 in your databunch, and seed=seed\n",
    "#in split_by_rand_pct\n",
    "seed = 42\n",
    "# python RNG\n",
    "random.seed(seed)\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    # Make a new figure\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    # Display the spectrogram on a mel scale\n",
    "    # sample rate and hop length parameters are used to render the time axis\n",
    "    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "    # Put a descriptive title on the plot\n",
    "    plt.title('mel power spectrogram')\n",
    "\n",
    "    # draw a color bar\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "    # Make the figure layout compact\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_spectrogram(audio_fname, image_fname):\n",
    "    y, sr = librosa.load(audio_fname, sr=None)\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "    fig1 = plt.gcf()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    fig1.savefig(image_fname, dpi=100)\n",
    "\n",
    "def audio_to_spectrogram(audio_dir_path, image_dir_path=None):\n",
    "    for paths in batch(audio_dir_path.ls(), 100):\n",
    "        for audio_path in paths:\n",
    "            audio_filename = get_filename(audio_path)\n",
    "            image_fname = audio_filename.split('.')[0] + '.png'\n",
    "            if image_dir_path:\n",
    "                image_fname = image_dir_path.as_posix() + '/' + image_fname\n",
    "            if Path(image_fname).exists(): continue\n",
    "            print(image_fname)\n",
    "            #plot_spectrogram(image_fname)\n",
    "            try:\n",
    "                save_spectrogram(audio_path.as_posix(), image_fname)\n",
    "            except ValueError as verr:\n",
    "                print('Failed to process %s %s' % (image_fname, verr))\n",
    "        # wait between every batch for xyz seconds\n",
    "        time.sleep(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:/Users/Madis/.fastai/data/FSDKaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ac9e7a91.wav</td>\n",
       "      <td>Church_bell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65ae847e.wav</td>\n",
       "      <td>Frying_(food)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32ec2454.wav</td>\n",
       "      <td>Computer_keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af7b5bab.wav</td>\n",
       "      <td>Scissors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7e8cd849.wav</td>\n",
       "      <td>Purr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname             labels\n",
       "0  ac9e7a91.wav        Church_bell\n",
       "1  65ae847e.wav      Frying_(food)\n",
       "2  32ec2454.wav  Computer_keyboard\n",
       "3  af7b5bab.wav           Scissors\n",
       "4  7e8cd849.wav               Purr"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'FSDKaggle2019.meta'/'train_curated_post_competition.csv')\n",
    "df = df.drop(columns =  ['license', 'freesound_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
